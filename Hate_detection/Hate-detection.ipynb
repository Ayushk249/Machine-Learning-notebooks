{"cells":[{"cell_type":"markdown","metadata":{"id":"veJkrjDkX-Ew"},"source":["## Installing dependencies and importing packages"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1748,"status":"ok","timestamp":1698745221685,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"Nu2CAYf1X-Ex"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2352,"status":"ok","timestamp":1698745224031,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"lYAu0ALajx_A"},"outputs":[],"source":["from tensorflow.python.saved_model import path_helpers"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1698745224032,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"9VUUoycQlPfI"},"outputs":[],"source":["from tensorflow_estimator.python.estimator.estimator_export import estimator_export"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1698745224033,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"IOORUmZIj8Vl","outputId":"fa807803-649b-4eda-9a9e-fb5955bed24f"},"outputs":[{"data":{"text/plain":["\u003cmodule 'tensorflow.python.saved_model.path_helpers' from '/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/path_helpers.py'\u003e"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["path_helpers"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1698745224033,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"TmFQJFsh9VW4"},"outputs":[],"source":["import fastai"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7630,"status":"ok","timestamp":1698745231641,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"1pZOH5R1X-Ez","outputId":"0da88fbb-30af-4bc7-99a3-5d82c7c549d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# A dependency of the preprocessing for BERT inputs\n","!pip install -q tensorflow-text"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41236,"status":"ok","timestamp":1698745272847,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"hTrpdAbGX-Ez","outputId":"42bb72ca-8b1c-4933-d791-e21b0064760c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers\u003c0.15,\u003e=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors\u003e=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers) (4.5.0)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.3.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}],"source":["!pip install -q tf-models-official\n","!pip install transformers"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20463,"status":"ok","timestamp":1698745293268,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"CUr5kCrMX-E0","outputId":"c09d8ee1-0a21-4f9a-d9d6-b1213dd605b9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["2.14.0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","import tensorflow.keras.backend as K\n","from scipy.stats import spearmanr\n","from math import floor, ceil\n","from transformers import *\n","from wordcloud import WordCloud, STOPWORDS\n","stopwords = set(STOPWORDS)\n","stopwords.add(\"RT\")\n","np.set_printoptions(suppress=True)\n","print(tf.__version__)\n","\n","import shutil\n","\n","from official.nlp import optimization  # to create AdamW optmizer\n","\n","import pickle\n","\n","tf.get_logger().setLevel('ERROR')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64126,"status":"ok","timestamp":1698745357382,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"AbZ8Wq8xaBfV","outputId":"635a2046-3ff3-42dd-cb58-af8a3eae7b06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1698745627906,"user":{"displayName":"Ayush Kumar","userId":"17497271996228360981"},"user_tz":-330},"id":"RtECXMsOX-E-","outputId":"b0667789-88b4-4db3-a28d-7ab69b233e64"},"outputs":[{"name":"stdout","output_type":"stream","text":["BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\n"]}],"source":["bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n","#bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n","\n","map_name_to_handle = {\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_base/2',\n","    'electra_small':\n","        'https://tfhub.dev/google/electra_small/2',\n","    'electra_base':\n","        'https://tfhub.dev/google/electra_base/2',\n","    'experts_pubmed':\n","        'https://tfhub.dev/google/experts/bert/pubmed/2',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n","}\n","\n","map_model_to_preprocess = {\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_preprocess/1',\n","    'electra_small':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'electra_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'experts_pubmed':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',\n","}\n","\n","tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","print(f'BERT model selected           : {tfhub_handle_encoder}')\n","print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n"]},{"cell_type":"markdown","metadata":{"id":"IiP9tXYSX-E2"},"source":["This is an unbalanced dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Y6LDtTbzX-E0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/35\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"name":"stdout","output_type":"stream","text":["628/628 [==============================] - 161s 245ms/step - loss: 0.1715 - accuracy: 0.6304 - val_loss: 0.7706 - val_accuracy: 0.7046\n","Epoch 2/35\n","628/628 [==============================] - 153s 244ms/step - loss: 0.0397 - accuracy: 0.7410 - val_loss: 0.6242 - val_accuracy: 0.7660\n","Epoch 3/35\n","628/628 [==============================] - 153s 244ms/step - loss: 0.0292 - accuracy: 0.8008 - val_loss: 0.6789 - val_accuracy: 0.7113\n","Epoch 4/35\n","628/628 [==============================] - 155s 247ms/step - loss: 0.0240 - accuracy: 0.8194 - val_loss: 0.5021 - val_accuracy: 0.7907\n","Epoch 5/35\n","628/628 [==============================] - 152s 242ms/step - loss: 0.0191 - accuracy: 0.8435 - val_loss: 0.4724 - val_accuracy: 0.8185\n","Epoch 6/35\n","628/628 [==============================] - 150s 238ms/step - loss: 0.0145 - accuracy: 0.8767 - val_loss: 0.3504 - val_accuracy: 0.8781\n","Epoch 7/35\n","628/628 [==============================] - 150s 238ms/step - loss: 0.0111 - accuracy: 0.9025 - val_loss: 0.5091 - val_accuracy: 0.8359\n","Epoch 8/35\n","628/628 [==============================] - 152s 242ms/step - loss: 0.0086 - accuracy: 0.9260 - val_loss: 0.4792 - val_accuracy: 0.8566\n","Epoch 9/35\n"," 49/628 [=\u003e............................] - ETA: 2:03 - loss: 0.0063 - accuracy: 0.9369"]}],"source":["PATH = '/content/drive/MyDrive/Crater_Internship/Hate_detection/labeled_data.csv'\n","# PATH = '/content/labeled_data.csv'\n","df = pd.read_csv(PATH)\n","nRowsRead = None\n","df0 = pd.read_csv(PATH, delimiter=',', nrows = nRowsRead)\n","df0.dataframeName = 'labeled_data.csv'\n","\n","# Changing Labels\n","\n","c=df0['class']\n","df0.rename(columns={'tweet' : 'text',\n","                  'class' : 'category'},\n","                    inplace=True)\n","a=df0['text']\n","b=df0['category'].map({0: 'hate_speech', 1: 'offensive_language',2: 'neither'})\n","\n","df= pd.concat([a,b,c], axis=1)\n","df.rename(columns={'class' : 'label'},\n","                    inplace=True)\n","\n","# Splitting the data between train, validation and test sets:\n","X_train_, X_test, y_train_, y_test = train_test_split(\n","    df.index.values,\n","    df.label.values,\n","    test_size=0.10,\n","    random_state=42,\n","    stratify=df.label.values,\n",")\n","X_train, X_val, y_train, y_val = train_test_split(\n","    df.loc[X_train_].index.values,\n","    df.loc[X_train_].label.values,\n","    test_size=0.10,\n","    random_state=42,\n","    stratify=df.loc[X_train_].label.values,\n",")\n","\n","df['data_type'] = ['not_set']*df.shape[0]\n","df.loc[X_train, 'data_type'] = 'train'\n","df.loc[X_val, 'data_type'] = 'val'\n","df.loc[X_test, 'data_type'] = 'test'\n","\n","df_train = df.loc[df[\"data_type\"]==\"train\"]\n","df_val = df.loc[df[\"data_type\"]==\"val\"]\n","df_test = df.loc[df[\"data_type\"]==\"test\"]\n","\n","# converting to tensors\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((df_train.text.values, df_train.label.values))\n","val_ds = tf.data.Dataset.from_tensor_slices((df_val.text.values, df_val.label.values))\n","test_ds = tf.data.Dataset.from_tensor_slices((df_test.text.values, df_test.label.values))\n","\n","train_ds = train_ds.shuffle(len(df_train)).batch(32, drop_remainder=False)\n","val_ds = val_ds.shuffle(len(df_val)).batch(32, drop_remainder=False)\n","test_ds = test_ds.shuffle(len(df_test)).batch(32, drop_remainder=False)\n","\n","# Selecting model\n","bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n","tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n","bert_model = hub.KerasLayer(tfhub_handle_encoder)\n","\n","# Weights for classes\n","hate, ofensive, neither = np.bincount(df['label'])\n","total= hate\n","\n","\n","+ ofensive + neither\n","weight_for_0 = (1 / hate)*(total)/3.0\n","weight_for_1 = (1 / ofensive)*(total)/3.0\n","weight_for_2 = (1 / neither)*(total)/3.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n","initial_output_bias = np.array([3.938462, 15, 5.])\n","\n","# model structure\n","def build_classifier_model(output_bias=None):\n","    if output_bias is not None:\n","        output_bias = tf.keras.initializers.Constant(output_bias)\n","        #print(output_bias)\n","\n","    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","    encoder_inputs = preprocessing_layer(text_input)\n","    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","    outputs = encoder(encoder_inputs)\n","    net = outputs['pooled_output']\n","    net = tf.keras.layers.Dense(512, activation=\"relu\")(net)\n","    net = tf.keras.layers.Dropout(0.2)(net)\n","#   net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","    net = tf.keras.layers.Dense(3, activation=\"softmax\", name='classifier', bias_initializer=output_bias)(net)\n","    return tf.keras.Model(text_input, net)\n","\n","\n","classifier_model = build_classifier_model(output_bias=initial_output_bias)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metrics = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","# epochs and optimizer\n","epochs = 35\n","steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n","num_train_steps = steps_per_epoch * epochs\n","num_warmup_steps = int(0.1*num_train_steps)\n","\n","init_lr = 3e-5\n","optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                          num_train_steps=num_train_steps,\n","                                          num_warmup_steps=num_warmup_steps,\n","                                          optimizer_type='adamw')\n","\n","classifier_model.compile(optimizer=optimizer,\n","                        loss=loss,\n","                        metrics=metrics)\n","\n","history = classifier_model.fit(x=train_ds,\n","                              validation_data=val_ds,\n","                              epochs=epochs,\n","                              # The class weights go here\n","                              class_weight=class_weight\n",")\n","\n","loss, accuracy = classifier_model.evaluate(test_ds)\n","\n","# predicting on test dataset\n","tweet = []\n","test_labels = []\n","predictions = []\n","for tweet, labels in test_ds.take(-1):\n","  tweet = tweet.numpy()\n","  test_labels.append(labels.numpy())\n","  predictions.append(classifier_model.predict(tweet))\n","\n","from itertools import chain\n","flatten_list = list(chain.from_iterable(predictions))\n","y_pred = np.argmax(flatten_list, axis=-1)\n","y_test = np.array(list(chain.from_iterable(test_labels)))\n","\n","a=df_test[\"text\"]\n","b=pd.Series(y_pred)\n","df2=pd.concat([a,b],axis=1)\n","\n","confusion_matrix(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fFh3eptZhAS"},"outputs":[],"source":["classifier_model.save(\"hate35.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7pIEkNweIgkX"},"outputs":[],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkMM9ASpmMcE"},"outputs":[],"source":["def Predict_class(text):\n","  dict={0: 'hate_speech', 1: 'offensive_language',2: 'neither hate_speech nor offensive'}\n","  test_tweet=np.array([text])\n","  prediction=classifier_model.predict(test_tweet)\n","  y_pred=np.argmax(prediction, axis=-1)[0]\n","  return dict[y_pred]\n","\n","Your_text=\"hello mom\"\n","Predict_class(Your_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aU9Z_9aFX-E6"},"outputs":[],"source":["# from wordcloud import WordCloud, STOPWORDS\n","# stopwords = set(STOPWORDS)\n","# stopwords.add(\"RT\")\n","\n","# print(type(STOPWORDS))\n","\n","# import random\n","\n","# def random_color_func(word=None, font_size=None, position=None,  orientation=None, font_path=None, random_state=None):\n","#     h = 344\n","#     s = int(100.0 * 255.0 / 255.0)\n","#     l = int(100.0 * float(random_state.randint(60, 120)) / 255.0)\n","#     return \"hsl({}, {}%, {}%)\".format(h, s, l)\n","\n","# wordcloud = WordCloud(\n","#                           background_color='white',\n","#                           stopwords=stopwords,\n","#                           max_words=200,\n","#                           max_font_size=60,\n","#                           random_state=42\n","#                          ).generate(str(df.loc[df[\"category\"]==\"offensive_language\"].text))\n","# print(wordcloud)\n","# fig = plt.figure(1)\n","# plt.imshow(wordcloud.recolor(color_func= random_color_func, random_state=3),\n","#            interpolation=\"bilinear\")\n","# plt.axis('off')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m09Lo-H5X-E7"},"outputs":[],"source":["# def random_color_func(word=None, font_size=None, position=None,  orientation=None, font_path=None, random_state=None):\n","#     h = 20\n","#     s = int(100.0 * 255.0 / 255.0)\n","#     l = int(100.0 * float(random_state.randint(60, 120)) / 255.0)\n","#     return \"hsl({}, {}%, {}%)\".format(h, s, l)\n","\n","# wordcloud = WordCloud(\n","#                           background_color='white',\n","#                           stopwords=stopwords,\n","#                           max_words=200,\n","#                           max_font_size=60,\n","#                           random_state=42\n","#                          ).generate(str((df.loc[df[\"category\"]==\"neither\"].text)))\n","# print(wordcloud)\n","# fig = plt.figure(1)\n","# plt.imshow(wordcloud.recolor(color_func= random_color_func, random_state=3),\n","#            interpolation=\"bilinear\")\n","# plt.axis('off')\n","# plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQX0GD3CX-E7"},"outputs":[],"source":["# stopwords.add(\"Name\")\n","\n","# def random_color_func(word=None, font_size=None, position=None,  orientation=None, font_path=None, random_state=None):\n","#     h = 180\n","#     s = int(100.0 * 255.0 / 255.0)\n","#     l = int(100.0 * float(random_state.randint(60, 120)) / 255.0)\n","#     return \"hsl({}, {}%, {}%)\".format(h, s, l)\n","\n","# wordcloud = WordCloud(\n","#                           background_color='white',\n","#                           stopwords=stopwords,\n","#                           max_words=200,\n","#                           max_font_size=60,\n","#                           random_state=42\n","#                          ).generate(str((df.loc[df[\"category\"]==\"hate_speech\"].text)))\n","# print(wordcloud)\n","# fig = plt.figure(1)\n","# plt.imshow(wordcloud.recolor(color_func= random_color_func, random_state=3),\n","#            interpolation=\"bilinear\")\n","# plt.axis('off')\n","# plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LpSGu0y5X-E-"},"source":["# Printing some Tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxDlPLkKX-E-"},"outputs":[],"source":["# for feat, targ in train_ds.take(1):\n","#   print ('Features: {}, Target: {}'.format(feat, targ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqCbNfKNX-FA"},"outputs":[],"source":["# bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"]},{"cell_type":"markdown","metadata":{"id":"qsuis7r2X-FA"},"source":["Let's try the preprocessing model on some text and see the output:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEKrXFGaX-FA"},"outputs":[],"source":["# for text_batch, label_batch in train_ds.take(1):\n","#   for i in range(1):\n","#     tweet = text_batch.numpy()[i]\n","#     print(f'Tweet: {text_batch.numpy()[i]}')\n","#     label = label_batch.numpy()[i]\n","#     print(f'Label : {label}')\n","\n","# text_test = ['this is such an amazing movie!']\n","# text_test = [tweet]\n","\n","\n","# text_preprocessed = bert_preprocess_model(text_test)\n","\n","# print(f'Keys       : {list(text_preprocessed.keys())}')\n","# print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n","# print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n","# print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n","# print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rnXb81Z2X-FB"},"outputs":[],"source":["# bert_model = hub.KerasLayer(tfhub_handle_encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_4ZNQFLX-FD"},"outputs":[],"source":["# classifier_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-FSj2RQsf4FQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lGVN9NsHX-FF"},"outputs":[],"source":["# dataset_name = 'mpl_hate_speech'\n","# saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n","\n","# classifier_model.save(saved_model_path, include_optimizer=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MoCAzA-zBMg"},"outputs":[],"source":["print(f'Loss: {loss}')\n","print(f'Accuracy: {accuracy}')"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}